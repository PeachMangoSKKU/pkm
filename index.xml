<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title/><link>https://shihyuho.github.io/pkm/</link><description>Recent content on</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><atom:link href="https://shihyuho.github.io/pkm/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://shihyuho.github.io/pkm/moc/ddd-moc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/moc/ddd-moc/</guid><description>DDD MOC Strategic Design Tactical Design</description></item><item><title/><link>https://shihyuho.github.io/pkm/moc/event-sourcing-moc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/moc/event-sourcing-moc/</guid><description>Event Sourcing MOC Event Sourcing 一定來自於 DDD , 簡單來說:
Start with your Domain Find the Bounded Context Find the Important Concepts Find the Dynamics in your Business Language Topics General Understanding You may NOT need a read model Guarantee Correctness when writing Handle Versioning Create a Snapshot of the Stream Re-Model Domain Dealing with Errors Reference 特別感謝以下所有 Link, 本 MOC 中的內容都是從其中所節錄出來, 再加上少部分自己的心得整理而成</description></item><item><title/><link>https://shihyuho.github.io/pkm/moc/kubernetes-moc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/moc/kubernetes-moc/</guid><description>Kubernetes MOC Assigning Pods</description></item><item><title/><link>https://shihyuho.github.io/pkm/moc/spring-moc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/moc/spring-moc/</guid><description>Spring MOC Externalized Configuration</description></item><item><title/><link>https://shihyuho.github.io/pkm/moc/umani-moc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/moc/umani-moc/</guid><description>Umani MOC &amp;ldquo;Umami&amp;rdquo; are: Sweetness, Sourness, Saltiness, Bitterness, and that oddball Umami. It&amp;rsquo;s a mixture of insights and ideas, concepts and connections, all mingling together to create that mysterious full mouthfeel that magnificently completes any meal for the mind.
Rime Input Method Engine Change Data Capture [[spaces/umani/keeping-your-fork-update-to-date]]</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/aggregate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/aggregate/</guid><description>Aggregate 包含了 Entities 跟 ValueObject 負責所有 Entites 跟 ValueObject 的 Invariants Aggregate 即 Transaction Boundary, 建議一個 Aggregate 應該只對應一個 Repository , 並在該 Repository 綁上 Transaction 使用名詞, 不要出現動詞 避免使用不精確的名詞 Interaction with other aggregate 如果是要協調調度兩個不同的聚合的情況下，一般我們會考慮是以 Application Service 來處理，或者是通過派發領域事件去跟另一個聚合做交互， domain service 還是比較隸屬於該聚合相關的業務話題的事物居多。
Aggregate Root 挑選 Aggregate 中的其中一個 Entity 最為 Root (根), 只有 Aggregate Root 持有整體的領域事件 (Domain Event)，並且決定何時發出去。
一個 Aggregate Root擁有 domain event list 就好像是一個汽車修理員隨身攜帶螺絲起子一樣是很自然的事情</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/bounded-context/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/bounded-context/</guid><description>Bounded Context 盡可能的具象化 等於是 Aggregate 的群組 Dealing with Relationships 找出各個 Bounded Context 的上下文
U: Upstream 上文 D: Downstream 下文 如果找到上下文之間有 cycle 關係, 代表這些參與 cycle 的 bounded context 的關係有問題, 有可能其實是同一個</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/bridge-pattern/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/bridge-pattern/</guid><description>Bridge Pattern 橋接模式最主要就是將你的物件切分成概念與行為(殼與肉)，達到極致的解偶獨立，例如，遙控器他只是一個塑膠殼(概念)搭配一個電子電路版(行為)，如果我將電子電路版做成通用，以後遙控器的殼可以跟隨市場上流行的板式直接使用我的電子電路版。
Class Diagram Abstraction: 將原本的主體抽換到只剩下虛擬的概念，例如(人類:只是吃喝拉撒睡的主體、遙控器:只是開機關機調整的主體)
Class Diagram RefineAbstraction: 根據不同的需求實作主體
Implementator: 將原本主體的實際功能抽離，成為這個的Hierarchy(繼承結構)，例如(人類:人類的吃和拉撒睡拉出在此結構實作)
ConcreteImplementator: 根據不同的需求開發真實的行為
![[spaces/ddd/attachments/bridge-pattern.png]]
Example 在 Application 中我們定義 repository interface, 也就是 Bridge Pattern 的 Abstraction, 其中只會列出該 aggregate 中會用到的動作
例如在 Balance Aggregate 中, 我們會使用到:
getCurrentBalance: 取得當前的餘額 save: 更新餘額 1 2 3 4 5 6 7 pacakge example.application.balance.repository; @FunctionInterface interface BalanceRepository { Balance getCurrentBalance(); void save(Balance balance); } 接的在 Infrastructure package 中去實作 Domain repository, 也就是 Bridge Pattern 的 RefineAbstraction, 這邊通常也是管理 Transaction 的地方, 而且這邊也不直接操作 Persistence framework (如 JPA), 取代代之的是傳入 Dao</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/command/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/command/</guid><description>Command 通常是 Event 的倒裝, 例如: Event 是買了鞋子, Command 就是 買鞋
便利貼顏色 使用藍色</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/domain-modeling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/domain-modeling/</guid><description>Domain Modeling Aggregate Event Storming 的 Aggregate 實作後比較像 Domain Modeling 的界線, 通常會再分:
Aggregate Root Entity Value Object Aggregate Root 可以從生命週期來看, 當某一件事在某個時間點結束時, 相關的資料也會跟的消失, 就樣就適合當成 Root
在 Root 中可以從 public getter, private setter 開始設計
怎麼找出 VO 或 Entity 先在 Event Storming 的 Aggregate 中, 試著找到所有相關的名詞, 使用紫色便條紙, 這可以是很細節
在這些紫色便條紙中, 依序往下區分
Value Object Descriptive aspect of domain, 是一種描述, 肚量 domain 的性質
Immutable value Non-identical life cycle concept Entity 在 Value Object 中, 有狀態, 生命週期的, 改成定義為 Entity 定義 Entity Id, Id 基本上也是 Value Object, 就算只有一個欄位也是這樣建議 Entity ID 可以是以下方式:</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/event/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/event/</guid><description>Event 事件，也稱領域事件，即不可抹滅的事實, 使用過去式表達
便利貼顏色 使用橘色 或使用紫色便利貼, 紫色代表一個長流程, 也就是橘色的集合 事件捕捉 透過 Event Storming 找出事件, 關鍵有：
統一語言 ubiquitous language 限界上下文 bounded context 即在不同上下文之間, 講不同語言
改系統，一定要有 business wish/value/goal，否則失敗率極高</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/example-mapping/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/example-mapping/</guid><description>Example Mapping Use Case 在 Bounded Context 中, 試著找出很多 Use Case, 使用黃色便條紙寫上
Rule 在黃色的 Use Case 中, 找出很多 Rule, 使用藍色的便條紙
Example 從 Rule 中找出範例, 使用綠色便條紙 範例應該包含 Use Case 的正反向流程 (成功/失敗) Question 過程中想到什麼問題, 列成紅色的便條紙
希望得到 發現並擴展問題域, 甚至找到新的 User Mapping Acceptance Tests Sharing Understanding Gherkin https://cucumber.io/
Given: 前置條件設定 When: 發生了一個事件, 通常可以就是 Command Then: 預期結果 And: 多個 Given (前置條件) 的串接 But: 多個 Then (預期結果) 的串接 Examples: 定義變數</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/invariants/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/invariants/</guid><description>Invariants 不變量, 並不是只不會改變, 而是指改變的結果是符合程式設計的假設與前提! 在 DDD 架構中, Aggregate 需要負責其不變量
Enforcing Invariants with Aggregates 當模型中的物件關係有複雜關聯時, 是很難的去確保其中部分物件變更時整體的一致性
Solution 我們將 Entities 跟 ValueObject 聚合在一起形成 Aggregate 並定義 Aggregate 的邊界。選擇一個 Entity 作為 Aggregate Root , 並且我們只在 Aggregate Root 中去存取 Aggregate 邊界內的物件。
對外我們也只開放 Aggregate Root 的引用, 任何外部都不能繞過 Aggregate Root 直接的對其內部物件修改, 這種安排可以確保任何針對 Aggregate 裡面的物件以及 Aggregate 本身的狀態修改都不會違反不變量 (Invariants)</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/repository/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/repository/</guid><description>Repository 一個 [[spaces/ddd/aggregate]] 對應一個 Repository
兩種類型 依據 DDD 紅皮書的分析，Repository有兩種：
Collection-like CRUD-like Martin Follower PoEAA書中的repository是collection-like，但一般我們常用的是CRUD-like，需要額外呼叫save儲存aggregate。所以當你決定使用Repository pattern，你要決定使用哪一種風格的repository。
的目 Repository 的目的是要隔離領域物件(aggregate)與資料庫操作。
從領域物件的角度來看 ，根本不需要知道 Repository 的實作, Ex: 有哪些 Entity? 對應多少個 Data Object?
Pattern 通常是分析到最後，才需要關心Repository的實作, 在 DDD 加上 Clean Architecture 的情況下, 實作套 [[spaces/ddd/bridge-pattern]] 通常就搞定了!
Repository 原本就是一個介面，就算你針對某個實作版本不滿意，不管是效能還是其他原因，換 Repository 的實作即可。
當然沒事不會常常換，因為換掉之後後端的資料庫可能需要隨著改變。如果已經有production的資料在上面，會比較麻煩。</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/strategic-design/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/strategic-design/</guid><description>Strategic Design 戰略
Event Command User Read Model Third Party Aggregate Bounded Context Subdomain 執行順序 匡圈 DDD 範圍, 在發想時如果已知超過範圍, 可使用粉紅色表示, 其代表另一個複雜流程 定義 Command (藍色) 跟 User(黃色) 在 Command 跟 Event 之中找 Logic (黃色), 勢必會打破原本的橘, 紫色 Aggregate 聚合所有便利貼 找 Bounded Context Sticky Note 橘色: 已經發生的事實，不可改變，使用過去式 紫色: 大流程, 即橘色的群組 粉紅: Third/External Party 黃色: User/Role 藍色: Command</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/subdomain/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/subdomain/</guid><description>Subdomain SubDomain 可分:
Generic Subdomain Support Subdomain Core Subdomain Generic Subdomain 輪子不用再造, 找其他現成軟體或其他廠商的 API, 如: email, sms, 加密等
Support Subdomain 用來支撐 core 的 subdomain
Core Subdomain 最關注的 domain, 通常是改造的目標</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/ddd/tactical-design/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/ddd/tactical-design/</guid><description>Tactical Design 戰術
提高系統存活率 Living Document - 讓文件語言跟程式語言儘量一至 Bubble - 讓一些還沒有要疏離的系統, Infrastructure - CICD, Auto test Architecture - Re-modular Module in Monolith first
Core Domain Pattern X軸: Model Complicity Y軸: Business Differentiation
Table stakes former core Short-term core Hidden core Black swan core ArchUnit 測試程式依賴的工具 https://www.archunit.org/use-cases
資料結構 maven submodule: bounded context aggregate 放 domain 中 Domain Modeling Example Mapping</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/aggregate-business-invariants/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/aggregate-business-invariants/</guid><description>Aggregate Business Invariants 首先 Aggregate 應負責其邊界內的 Invariants , 再來 Aggregate 本身也應該是 Transaction Boundary, 因此 Aggregate 必須也可以保證在多個 transactions 下的正確性。
透過 Optimistic Concurrency Control 我們可以確保在多個 Transactions 下都可以依照順序的執行完成, 且不會互相影響, 簡單來就是說每個 Transaction 都需要確認資料沒有被其他的 Trnasaction 異動過。
Last Event Number 從 Stream 建立出 Aggregate 時, 必須記住 last event number, 在將新的 event 放入 Stream 前, 必須檢查當前的 Stream 的 event number
當 event number 一樣時代表沒有其他 Transaction 有增加 event, 這時我們才可以寫入新的 event
反之當不一樣時, 就不能寫入新的 event 進 Stream
Source Code Example Kafka 也許 Kafka offset 也可以用, 但可能要確認一下 Kafka 是否已經支援了</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/copy-transform/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/copy-transform/</guid><description>Copy Transform 首先先定義多久要 Transform 一次, 例如我們每年做一次, 這樣我們會在前一年的最後增加 Deactivated event, 並再次年增加一個 Initialized event, 並將兩個 event 連接起來
這兩個基本上是不同的 Stream 對應 Queue, 會是不同的 Kafak topic 因此 App 在讀取到 Deactivated event 該怎麼自動切換到所連接的 Initialized event 的 Stream 呢?
這邊大概是最精華所在, 講解也沒透露他們怎麼做, 但如果可以重啟 App 來做切換那會簡單很多</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/create-a-snapshot-of-the-stream/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/create-a-snapshot-of-the-stream/</guid><description>Create a Snapshot of the Stream 時間一久當 Stream 越來越大以後, 程式該如何應對 Large Stream 呢? 基本上我們的程式不處理 Large Stream!
而是我們透過 Copy Transform 方式來建立 Strea 的 Snapshot, 來讓程式維持讀取 Small Stream!</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/dealing-with-errors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/dealing-with-errors/</guid><description>Dealing with Errors 假設過去有一個 Event 的內容發生問題, 該如何處理呢? 千萬不可以直接 update event store, 畢竟 event store 為 Single Source of Truth , 既然是事實怎麼可以修改?
Use Compensation Events 我們透過補償事件來處理錯誤
Partial Compensation 透過 Corrected Event 來修正過去的部分錯誤, 例如我們想把 Euro 文字改成 EUR:
這個模式時間久了, 在回顧部分 Stream 時不容易的去了解前因後果, 而是必須還要查看完整的 Stream 才知道原因
Full Compensation 透過 Cancelled Event 來完整的取消過去的錯誤, 情境一樣我們只想把 Euro 文字改成 EUR, 但這次是取消之前的錯誤 event:
這個模式下, 以 Stream 的角度來看是比較明確的且比較清楚的</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/double-write/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/double-write/</guid><description>Double Write Producer 將兩個版本的 event 都發佈, 而我們預期 Consumer 應該要可以自己判斷該處理哪個版本的 event</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/general-understanding/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/general-understanding/</guid><description>General Understanding 在經過 DDD 的洗禮之後, 我們會有很多 Event , 包含了 Event type 跟 Data。我們會將這些 Event 有順序性的儲存在 Stream 中 (通常就採用 Event 的建立順序)，然後再將這些 Stream 儲存到 EventStore 中, 並為每個 Event 產生獨一無二的 ID。
接著我們會透過 Projection 將 Stream 中的所有 Events 去計算出 Aggregate 的 current state, 為了方便使用, 我們也可以將 current state 儲存成一個 Read Model</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/guarantee-correctness-when-writing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/guarantee-correctness-when-writing/</guid><description>Guarantee Correctness when writing Validation against a read model is prone to INCONSISTENCIES
Read Model 所提供的資訊, 同時有機會被多個服務或是 Thread 使用, 這時候就會造成一些不一致的問題!
有個經典的提款情境: 兩個 Thread 在檢查同一帳戶餘額時都是通過的, 但一起下提款 Command 時, 你的帳戶就超支囉!
我們有使用兩個方式來解決這個問題
Manage Transactions With a Database Aggregate Business Invariants Reference Messaging as the Single Source of Truth</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/handle-versioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/handle-versioning/</guid><description>Handle Versioning 在 Java 世界中, 我們通常透過 Jar 來 share source code, 假設現在是 1.0.0 jar 同時給 Producer 跟 Consumer 使用:
當 Producer 調整 event 開始發佈 2.0.0 時, 而所有的 Consumer 又還沒完全跟上時, 我們該怎麼辦?
Solutions Double Write Upcaster Or&amp;hellip; we don&amp;rsquo;t upgrade event Don&amp;rsquo;t Upgrade event 任何 Event schema 的異動都必須確保新的 schema 可以被舊的 handler 讀取使用，這樣你才可以異動之, 若不行, 它就是一個新的 Event, 你應該要有對應的新 handler!
反之, 新的 handler 也應該要可以讀取處理舊的 schema, 若不行, 他也就是一個新的 Event, 你應該也要有對應的新 handler!</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/manage-transactions-with-database/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/manage-transactions-with-database/</guid><description>Manage Transactions with a database 這種狀況我們可以選擇在 Event Store 之前放一個 Database 去管理 Transaction
我們使用一個 Database 擋在 Event Store 之前, 再使用 CDC 抓取 Event Stream 到 Event Store 中, 在個 Database 即稱為 Transaction Database
以下圖為例
Transaction Database 使用 Couchbase Event Store 使用 Kafka 當 Order Service 接到 Bug Command 時, 寫的是 Couchbase, 在這邊管理多個 Order Service Instance 或多個 Thread 的 Transaction
當 Couchbase 資料有變化時, 會被 CDC (Kafka connect) 發佈到 Kafka 中</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/projection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/projection/</guid><description>Projection Projection 就是用來處理 event 的程式邏輯, 基本上就是一推 Event Handlers!
例, 我們有以下 event:
UserCreated UserOnboarded UserRelocated 則 Current User Projection 的內容大概是:
而產出會是 Aggregate</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/read-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/read-model/</guid><description>Read Model Read Model 可以說是在 Event Store 中, 特定的 Event of Stream 的產出。
以程式來看, 大概像是:
1 2 var readModel = Stream.of(events) .leftFold(handlers) 這個產出, 通常也就是會被儲存在每個服務自己的 db 中</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/remodel-domain/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/remodel-domain/</guid><description>Re-Model Domain 當我們需要 Re-Model Domain 時, 例如打散 event, 該怎麼做呢? 基本上跟 Copy Transform 一樣概念:</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/upcaster/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/upcaster/</guid><description>Upcaster Upcaster 通常擋在 Queue 跟 Consumer 之間, 它負責做事件版本的轉換
Trafe off 要注意的是, 當時間一久, 這種模式下 Upcaster 很容易的會失控跟維護, 因次他會有有大量的轉換邏輯在其中</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/event-sourcing/you-may-not-need-a-read-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/event-sourcing/you-may-not-need-a-read-model/</guid><description>You may NOT need a read model Read Model 會有一些 Trade off:
最終一致性 該如何 Replays and Rebuilds 該如何 Re-Deliveries Read Db 的維運成本 換個角度想, 如果不要有 Read Model 呢?
我們如果在讀取 Event Store 時, 就依照 Aggregate ID 過濾 Stream, 把 Stream 最小化
回到使用端, 在 runtime 要取得 current state 時, 程式在即時的去運算出 current state 的 Aggregate
由於我們把 Stream 最小化了, 效能仍不錯, 而且也沒有了那些 Trade off!
如果需要透過條件去查詢, 可能要使用到一些 Event Store 所提供 Category Projection 了!
在 Event Store 中就可以先將 Event 分類後再讀出 Stream 了!</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/kubernetes/assigning-pods/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/kubernetes/assigning-pods/</guid><description>Assigning Pods 在部署 Deployment 時, 有些情況我們會希望 Kubernetes 依照我們的需求來安排部署的 Node, 例如:
當我們開多份 Replicas 時, 希望這些 Replicas 時儘量不要安排到同一個 Node 上 不同的部署但性質相雷同的程式, 例如資源需求 (如 CPU 運算) 較高等, 希望儘量不要安排到同一個 Node 上 Affinity 在 spec.affinity 下一共有 podAffinity (正向) 或 podAntiAffinity (反向), 這是用來約束 Kubernetes 該怎麼安排 Pod 到 Node 上, 這兩種 affinity 中都有兩種 type 可以使用:
requiredDuringSchedulingIgnoredDuringExecution - Hard requirement, 要求 Kubernetes 依照設定安排, 沒滿足就不部署 Pod preferredDuringSchedulingIgnoredDuringExecution - Soft requirement, 建議 Kubernetes 儘量滿足設定安排, 無法滿足仍要部署 Pod Use Case 以下我們範例是一個常見的需求: 建議 Kubernetes 將多個 replicas 儘量分散到不同的 Node 中</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/spring/externalized-configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/spring/externalized-configuration/</guid><description>Externalized Configuration Spring Boot 2.4 改進了處理 application.properties 等設定檔的讀取的模式, 調整後的邏輯多支援了配置外部的載入方式, 此篇提供了一個簡單的 workshop 來介紹怎麼應用到雲平台 (Cloud Platform) 的部署上
如果是用 Spring Boot 2.4+ 但想要使用舊的邏輯, 可設定 spring.config.use-legacy-processing=true
Config Data File Spring Boot 在啟動時會參考許多設定來源 (Configuration Sources), Spring 也提供了 許多方式來配置 , 這些源包含了以下常見的 (順序是重要的):
Config data file(如 application.properties) OS environment variables Java System properties (System.getProperties()). Command-line arguments Testing config &amp;hellip; etc 其中在讀取 Config data file 的階段順序如下：
Application properties packaged inside your jar (application.properties and YAML variants).</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/umani/json-schema/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/umani/json-schema/</guid><description>JSON Schema JSON Schema 是一種宣告式語言, 可以定義並驗證 JSON 物件的結構, Java 套件可參考 everit-org/json-schema Reference Introduction to JSON Schema in Java</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/umani/optimistic-concurrency-control/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/umani/optimistic-concurrency-control/</guid><description>Optimistic Concurrency Control 樂觀鎖 (簡稱 OCC), 是一種並行控制的方法。
簡單的實作方式就是, 找資料其中一個欄位作為判斷條件, 如 @Version 或是 最後修改時間, 在資料異動時將該欄位一併作為 Where 條件去執行, 若 update row = 0 即代表資料已過期。
如此我們就可以確保同時多個 Transaction 針對同一筆資料異動的順序性, 不會發生後蓋前等狀況。</description></item><item><title/><link>https://shihyuho.github.io/pkm/spaces/umani/single-source-of-truth/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/umani/single-source-of-truth/</guid><description>Single Source of Truth 事實的唯一來源, 在系統設計與理論中, 事實的唯一來源是構建信息模型和關聯的數據模式的實踐, 一個 Application 應該只引用或參考自一個主要的事實的資料源</description></item><item><title>Change Data Capture</title><link>https://shihyuho.github.io/pkm/spaces/umani/cdc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/umani/cdc/</guid><description>Change Data Capture 縮寫 CDC, 意指如何發現並捕獲資料源 (Source Database) 的資料變化, 常見的解決方案有:
Log-based ETL Trigger-based Log-based 透過工具監控 Source Database 的 Transaction Log, 常見的工具如: Debezium Challenges 需配合所挑選的 Tool 的相關設定, 如 Debezium 官方 所要求的權限 可能客戶的 DBA 會認爲過大 部分 Database 需要配合設定, 如 Oracle 需要啓用 Archive Log, 若客戶本身沒使用這些功能, 則開啓後對客戶環境的穩定度是一個挑戰 ETL 透過約定好的 Audit Columns (如 createdDate, lastModifiedDate) 來進行 ETL
實作一個 CDC App, 定期以 Audit Columns 作爲判斷依據來查詢 Source Database, 將捕捉到的異動資料同步到 Target Database 中
Challenges 要被監控的 Table 都必須要有 Audit Columns 人爲操作 DB 也必須都要更新 Audit Columns 視業務需求, 需要有額外的 Source Database 刪除資料的處理流程 Source Database 會有額外的效能消耗給 CDC App 定期的查詢 CDC App 定期查詢的週期決定了 Target Database 的資料時間差 Trigger-based 透過在 Source Database 中設定 Database Trigger 來監控目標 Table</description></item><item><title>Home</title><link>https://shihyuho.github.io/pkm/+home/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/+home/</guid><description>Main Maps Umani MOC DDD MOC Event Sourcing MOC Kubernetes MOC Spring MOC Private Stuff Projects MOC Private pages doesn&amp;rsquo;t get published!</description></item><item><title>Rime Input Method Engine</title><link>https://shihyuho.github.io/pkm/spaces/umani/Rime-Input-Method-Engine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shihyuho.github.io/pkm/spaces/umani/Rime-Input-Method-Engine/</guid><description>中州韻輸入法引擎 我是用注音輸入法，一直以來都使用 MacOS Big Sur 中的內建的注音輸入法，但真的越來越慢，慢到真的受不了了&amp;hellip;
找個時間收尋並且嘗試了一下其他支援 MacOS 中的注音輸入法, 包含了
Yahoo輸入法 小麥輸入法 超注音 中州韻輸入法引擎 其中中州韻輸入法引擎最吸引我的眼球，效能好，設定方式很工程師(誤)，本身開源，GitHub 上一直都有持續的維護更新等等，都很符合我的口味！
因此此篇稍微記錄一下安裝跟配置方式，提供日後 OS 重裝後的參考
Install 可以從官方 Downlaod Page 下載安裝檔，或使用 Homebrew 來安裝:
1 brew install --cask squirrel Setup 安裝好後, 所有相關的配置可以從 menu 中的輸入法中進入, 更改配置後都需要重新點擊 Deploy 始得生效
Custom Settings 點選 Settings, 會開啟 Rime 的目錄, MacOS 預設目錄在:
1 /Users/{username}/Library/Rime 在該錄中建立 default.custom.yaml 檔案
1 touch /Users/{username}/Library/Rime/default.</description></item></channel></rss>